{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94b13ed",
   "metadata": {},
   "source": [
    "# Chapter 6. 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f1029bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.11 (main, Apr 20 2023, 19:02:41) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "772a0d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 29 23:45:32 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.105.01   Driver Version: 515.105.01   CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "|  0%   38C    P8    22W / 170W |   2196MiB / 12288MiB |     17%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      2297      G   /usr/lib/xorg/Xorg                292MiB |\r\n",
      "|    0   N/A  N/A      2434      G   /usr/bin/gnome-shell               27MiB |\r\n",
      "|    0   N/A  N/A     26387      G   ...863751312754158865,262144       62MiB |\r\n",
      "|    0   N/A  N/A     28297      C   ...3/envs/py31011/bin/python     1789MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e71e040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated Memory:0.00 MB\n",
      "Cached Memory: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# GPU 메모리 사용량 확인\n",
    "if device.type ==\"cuda\":\n",
    "    allocated_memory = torch.cuda.memory_allocated(device = device)\n",
    "    cached_memory = torch.cuda.memory_reserved(device = device)\n",
    "\n",
    "print(f\"Allocated Memory:{allocated_memory / 1024 ** 2:.2f} MB\")\n",
    "print(f\"Cached Memory: {cached_memory / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be12f6",
   "metadata": {},
   "source": [
    "**(서론)**\n",
    "\n",
    "언젠가 한 번쯤 문서를 요약해야 할 때가 있습니다. 요약할 문서는 연구 논문이나 재무 실적 보고서 아니면 이메일 스레드일지도 모릅니다. 생각해보면 이런 작업에는 긴 단락을 이해하고, 관련 내용을 추론하고, 원래 문서의 주제를 통합해 유창한 텍스트를 생성하는 등 다양한 능력이 필요합니다. 또 기사를 정확하게 요약하는 방법과 법률 계약서를 요약하는 방법은 매우 다르기 때문에 정교한 수준의 도메인 일반화가 필요합니다. 이런 이유로 트랜스포머를 포함한 자연어 모델에게 텍스트 요약은 어려운 작업니다. 이런 어려움에도 불구하고 텍스트 요약은 도메인 전문가의 작업 속도를 크게 높이고 기업에서 내부 지식을 집약하고, 계약을 요약하고 소셜 미디어를 위한 자동 콘텐츠를 생성하는 등의 작업에 사용됩니다. \n",
    "\n",
    "\n",
    "이와 관련된 도전 과제를 이해하기 위해 이 장은 사전 훈련된 트랜스포머를 사용해 문서를 요약하는 방법을 알아보겠습니다. 요약은 입력과 출력이 텍스트인 고전적인 시퀀스-투-시퀀스 작업니다. 1장에서 보았듯이 요약에는 인코더-디코더 트랜스포머가 잘 맞습니다. \n",
    "\n",
    "\n",
    "이 장에서는 인코더-디코더 모델을 만들어 여러 사람이 주고 받은 대화를 간결하게 요약하겠습니다. \n",
    "\n",
    "하지만 그 전에 요약에 사용하는 대표적인 데이터 셋인 CNN/DAilyMail 말뭉치를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c3c5fd",
   "metadata": {},
   "source": [
    "## 6.1 CNN/DailyMail 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfba8f1",
   "metadata": {},
   "source": [
    "CNN/DailyMail 데이터셋은 300,000개 뉴스 기사와 요약의 쌍으로 구성됐습니다. 요약은 CNN과 DailyMail이 기사에 첨부한 글머리 목록의 내용인데, 요약이 본문에서 추출되지 않고 추상적이라는 중요한 특징이 있습니다. 즉, 단순한 발췌가 아니라 새로운 문장으로 구성됐다는 이야기입니다. 이 데이터 셋은 허깅 페이스 허브(https://huggingface.co/datasets/cnn_dailymail)에서 제공합니다. 여기서는 요약을 위해 익명화 처리를 하지 않은 3.0.0 버전을 사용하겠습니다. 4장에서 서브셋을 선택한 대와 비슷한 방식으로 version 매개변수를 사용해 버전을 선택합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3254d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d32d8a05ae4326b5687768fa53a929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/8.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e87bc8bc904c25a2af9b8bc048dbf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/9.88k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57db50374e224a02a0e3c65f25a25c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/15.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cnn_dailymail/default to /home/bread/.cache/huggingface/datasets/cnn_dailymail/default/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac763805c994979b7ef5904138010d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84f8f6cdb2a425383cde12458293fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/159M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a77b2a73c34fd79157a77c3cdacd31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/376M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7c5c3cc7e54c99b70ceef34c34db01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/12.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f76307369c8477599b4b9d6a2fb0b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/661k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4283ff631d8e418088ef27e2025a956b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/572k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cnn_dailymail downloaded and prepared to /home/bread/.cache/huggingface/datasets/cnn_dailymail/default/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f610cb8bd6040e3942e0c30bd369008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성: ['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", version = \"3.0.0\")\n",
    "print(f\"특성: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea8f9683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated Memory:0.00 MB\n",
      "Cached Memory: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# GPU 메모리 사용량 확인\n",
    "if device.type ==\"cuda\":\n",
    "    allocated_memory = torch.cuda.memory_allocated(device = device)\n",
    "    cached_memory = torch.cuda.memory_reserved(device = device)\n",
    "\n",
    "print(f\"Allocated Memory:{allocated_memory / 1024 ** 2:.2f} MB\")\n",
    "print(f\"Cached Memory: {cached_memory / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8856baad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result : 512.67 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# 현재 프로세스의 메모리 정보 얻기\n",
    "process = psutil.Process()\n",
    "print(f\"result : {process.memory_info().rss / 10**6:.2f} MB\")  # 현재 사용 중인 메모리 양 (Resident Set Size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ec68b",
   "metadata": {},
   "source": [
    "이 데이터 셋은 세가지 특성이 있습니다. \n",
    "\n",
    " - 뉴스 기사를 담은 article\n",
    " \n",
    " - 요약에 해당하는 highlights\n",
    " \n",
    " - 기사의 고유 아이디 id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "740042bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 기사 (500개 문자 발췌, 총 길이: 4051):\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most s\n",
      "\n",
      " 요약 (길이: 281):\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n"
     ]
    }
   ],
   "source": [
    "# 기사 중 하나의 내용을 발췌함\n",
    "\n",
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\" 기사 (500개 문자 발췌, 총 길이: {len(sample[\"article\"])}):\"\"\")\n",
    "print(sample[\"article\"][:500])\n",
    "print(f'\\n 요약 (길이: {len(sample[\"highlights\"])}):')\n",
    "print(sample[\"highlights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa137909",
   "metadata": {},
   "source": [
    "기사가 요약에 비해 매우 긴 경우도 있습니다. 이 경우 17배나 차이가 납니다. 대부분 트랜스포머 모델의 문맥 크기가 몇 단락에 해당하는 분량인 1,000개 토큰 정도로 제한되므로, 긴 기사는 트랜스포머 모델에 문제를 일으깁니다. 이를 처리하는 표준적이면서 가장 단순한 방법은 모델의 문맥 크기에 맞춰 텍스트를 자른 것입니다. 텍스트 끝부분에 중요한 정보가 있다면 사라지겠지만, 이는 모델 구조의 제약으로 생기는 불가피한 선택입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff005db",
   "metadata": {},
   "source": [
    "## 6.2 텍스트 요약 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8bb74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf364a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96db240d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b59ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc6f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb31eb14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c51a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2072a5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a79437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55788d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85377401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348b159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
